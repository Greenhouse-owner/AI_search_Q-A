# ai_bot.py
import os
import asyncio
from typing import Optional, Generator, List, Dict, Any, Union
from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
from qwen_agent.gui import WebUI
import warnings
import gradio as gr  # type: ignore
import time
import base64
import urllib.parse
import json5  # type: ignore
from es_retrieval_tool import ElasticsearchRetrievalTool

warnings.filterwarnings("ignore")

# æ­¥éª¤ 1ï¼šæ·»åŠ ä¸€ä¸ªåä¸º `my_image_gen` çš„è‡ªå®šä¹‰å·¥å…·ã€‚
@register_tool('my_image_gen')
class MyImageGen(BaseTool):
    # `description` ç”¨äºå‘Šè¯‰æ™ºèƒ½ä½“è¯¥å·¥å…·çš„åŠŸèƒ½ã€‚
    description = 'AI ç»˜ç”»ï¼ˆå›¾åƒç”Ÿæˆï¼‰æœåŠ¡ï¼Œè¾“å…¥æ–‡æœ¬æè¿°ï¼Œè¿”å›åŸºäºæ–‡æœ¬ä¿¡æ¯ç»˜åˆ¶çš„å›¾åƒ URLã€‚'
    # `parameters` å‘Šè¯‰æ™ºèƒ½ä½“è¯¥å·¥å…·æœ‰å“ªäº›è¾“å…¥å‚æ•°ã€‚
    parameters = [{
        'name': 'prompt',
        'type': 'string',
        'description': 'æœŸæœ›çš„å›¾åƒå†…å®¹çš„è¯¦ç»†æè¿°',
        'required': True
    }]

    def call(self, params: Union[str, Dict], **kwargs) -> str:
        # `params` æ˜¯ç”± LLM æ™ºèƒ½ä½“ç”Ÿæˆçš„å‚æ•°ã€‚
        if isinstance(params, dict):
            prompt = params['prompt']
        else:
            prompt = json5.loads(params)['prompt']
        prompt = urllib.parse.quote(prompt)
        return json5.dumps(
            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},
            ensure_ascii=False)


def init_agent_service(mode: str = "full"):
    """åˆå§‹åŒ–åŠ©æ‰‹æœåŠ¡"""
    # æ­¥éª¤ 2ï¼šé…ç½®æ‚¨æ‰€ä½¿ç”¨çš„ LLMã€‚
    llm_cfg = {
        'model': 'qwen-max',
        'model_server': 'dashscope',
        'api_key': os.getenv('DASHSCOPE_API_KEY'),
        'generate_cfg': {
            'top_p': 0.8
        }
    }

    # è·å–æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶
    file_dir = os.path.join(os.path.dirname(__file__), 'docs')
    files = []
    if os.path.exists(file_dir):
        for file in os.listdir(file_dir):
            file_path = os.path.join(file_dir, file)
            if os.path.isfile(file_path):
                files.append(file_path)
    print('çŸ¥è¯†åº“æ–‡ä»¶åˆ—è¡¨:', files)

    if mode == "simple":
        # ç®€å•æ¨¡å¼ï¼šä»…å›¾åƒç”Ÿæˆå’Œä»£ç è§£é‡Šå™¨
        system_instruction = '''ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚
åœ¨æ”¶åˆ°ç”¨æˆ·çš„è¯·æ±‚åï¼Œä½ åº”è¯¥ï¼š
- é¦–å…ˆç»˜åˆ¶ä¸€å¹…å›¾åƒï¼Œå¾—åˆ°å›¾åƒçš„urlï¼Œ
- ç„¶åè¿è¡Œä»£ç `request.get`ä»¥ä¸‹è½½è¯¥å›¾åƒçš„urlï¼Œ
- æœ€åä»ç»™å®šçš„æ–‡æ¡£ä¸­é€‰æ‹©ä¸€ä¸ªå›¾åƒæ“ä½œè¿›è¡Œå›¾åƒå¤„ç†ã€‚
ç”¨ `plt.show()` å±•ç¤ºå›¾åƒã€‚
ä½ æ€»æ˜¯ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚'''
        tools_list: List[Union[str, Dict, BaseTool]] = ['my_image_gen', 'code_interpreter']
        
        bot = Assistant(llm=llm_cfg,
                        system_message=system_instruction,
                        function_list=tools_list,
                        files=files)
        return bot

    elif mode == "elasticsearch":
        # Elasticsearchæ¨¡å¼ï¼šä½¿ç”¨è‡ªå®šä¹‰Elasticsearchæ£€ç´¢å·¥å…·
        system_instruction = '''ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚
åœ¨æ”¶åˆ°ç”¨æˆ·çš„è¯·æ±‚åï¼Œä½ åº”è¯¥ï¼š
- é¦–å…ˆï¼Œæ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œè°ƒç”¨æ£€ç´¢å·¥å…·ä»çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯ã€‚
- ç„¶åï¼Œç»“åˆæ£€ç´¢åˆ°çš„ä¿¡æ¯å’Œä½ çš„çŸ¥è¯†ï¼Œç”Ÿæˆä¸€ä¸ªå…¨é¢ã€å‡†ç¡®çš„å›ç­”ã€‚
- å¦‚æœç”¨æˆ·è¦æ±‚ç”»å›¾ï¼Œè¯·è°ƒç”¨`my_image_gen`å·¥å…·ã€‚
ä½ æ€»æ˜¯ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚'''

        # å®ä¾‹åŒ–æˆ‘ä»¬è‡ªå®šä¹‰çš„ ES æ£€ç´¢å·¥å…·
        es_retrieval = ElasticsearchRetrievalTool(cfg={
            'password': 'your_password' 
        })

        # å®šä¹‰æ™ºèƒ½ä½“è¦ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
        tools_list = [es_retrieval, 'my_image_gen', 'code_interpreter']  # type: ignore
        
        bot = Assistant(llm=llm_cfg,
                        system_message=system_instruction,
                        function_list=tools_list,
                        files=files)
        return bot

    elif mode == "rag":
        # RAGæ¨¡å¼ï¼šåŸºç¡€Elasticsearch RAG
        system_instruction = '''ä½ æ˜¯ä¸€ä¸ªåŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„AIåŠ©æ‰‹ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ©ç”¨æ£€ç´¢å·¥å…·ä»çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾æœ€ç›¸å…³çš„ä¿¡æ¯ï¼Œå¹¶ç»“åˆè¿™äº›ä¿¡æ¯ç»™å‡ºä¸“ä¸šã€å‡†ç¡®çš„å›ç­”ã€‚'''

        # RAG é…ç½® - æ¿€æ´»å¹¶é…ç½® Elasticsearch åç«¯
        rag_cfg = {
            "rag_backend": "elasticsearch",
            "es": {
                "host": "https://localhost",
                "port": 9200,
                "user": "elastic",
                "password": "your_password"
                "index_name": "my_insurance_docs_index"
            },
            "parser_page_size": 500
        }
        
        bot = Assistant(
            llm=llm_cfg,
            system_message=system_instruction,
            files=files,
            rag_cfg=rag_cfg
        )
        return bot

    else:  # full mode
        # å®Œæ•´æ¨¡å¼ï¼šå…·å¤‡ Elasticsearch RAG å’Œç½‘ç»œæœç´¢èƒ½åŠ›
        system_instruction = '''ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä¼˜å…ˆåˆ©ç”¨æ£€ç´¢å·¥å…·ä»æœ¬åœ°çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚
å¦‚æœæœ¬åœ°çŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå†ä½¿ç”¨ tavily_search å·¥å…·ä»äº’è”ç½‘ä¸Šæœç´¢ï¼Œå¹¶ç»“åˆè¿™äº›ä¿¡æ¯ç»™å‡ºä¸“ä¸šã€å‡†ç¡®çš„å›ç­”ã€‚'''

        # RAG é…ç½®
        rag_cfg = {
            "rag_backend": "elasticsearch",
            "es": {
                "host": "https://localhost",
                "port": 9200,
                "user": "elastic",
                "password": "your_password",
                "index_name": "my_insurance_docs_index"
            },
            "parser_page_size": 500
        }

        # MCP å·¥å…·é…ç½® - æ–°å¢ tavily-mcp
        tools_cfg: List[Union[str, Dict, BaseTool]] = [{
            "mcpServers": {
                "tavily-mcp": {
                    "command": "npx",
                    "args": ["-y", "tavily-mcp@0.1.4"],
                    "env": {
                        "TAVILY_API_KEY": os.getenv('TAVILY_API_KEY', "YOUR_TAVILY_API_KEY")
                    },
                    "disabled": False,
                    "autoApprove": []
                }
            }
        }]
        
        bot = Assistant(
            llm=llm_cfg,
            system_message=system_instruction,
            function_list=tools_cfg,
            files=files,
            rag_cfg=rag_cfg
        )
        return bot


# å…¨å±€å˜é‡
bots = {
    "simple": init_agent_service("simple"),
    "elasticsearch": init_agent_service("elasticsearch"),
    "rag": init_agent_service("rag"),
    "full": init_agent_service("full")
}
session_histories = {}

def get_session_id():
    return str(time.time())

def stream_predict(query: str, history: list, session_id: str, mode: str = "full") -> Generator:
    """Gradio çš„æ ¸å¿ƒé¢„æµ‹å‡½æ•° - æ”¯æŒæµå¼å“åº”"""
    if session_id not in session_histories:
        session_histories[session_id] = []
    
    messages = session_histories[session_id]
    messages.append({'role': 'user', 'content': query})
    
    history[-1][1] = ""
    full_response = ""

    bot = bots.get(mode, bots["full"])
    for response in bot.run(messages=messages):
        if response and response[-1]['role'] == 'assistant':
            new_text = response[-1]['content']
            if new_text != full_response:
                delta = new_text[len(full_response):]
                history[-1][1] += delta
                full_response = new_text
                yield history

    messages.append({'role': 'assistant', 'content': full_response})
    session_histories[session_id] = messages

def predict(query, history, session_id, mode: str = "full"):
    """Gradio çš„æ ¸å¿ƒé¢„æµ‹å‡½æ•° - éæµå¼å“åº”"""
    if session_id not in session_histories:
        session_histories[session_id] = []
    
    messages = session_histories[session_id]
    messages.append({'role': 'user', 'content': query})
    
    response_text = ""
    bot = bots.get(mode, bots["full"])
    for response in bot.run(messages=messages):
        if response and response[-1]['role'] == 'assistant':
            response_text = response[-1]['content']
            
    messages.append({'role': 'assistant', 'content': response_text})
    session_histories[session_id] = messages
    
    history[-1][1] = response_text
    return history

def app_tui(mode: str = "full"):
    """ç»ˆç«¯äº¤äº’æ¨¡å¼
    
    æä¾›å‘½ä»¤è¡Œäº¤äº’ç•Œé¢ï¼Œæ”¯æŒï¼š
    - è¿ç»­å¯¹è¯
    - æ–‡ä»¶è¾“å…¥
    - å®æ—¶å“åº”
    """
    try:
        # åˆå§‹åŒ–åŠ©æ‰‹
        bot = bots.get(mode, bots["full"])

        # å¯¹è¯å†å²
        messages = []
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                query = input('user question: ')
                
                # è¾“å…¥éªŒè¯
                if not query:
                    print('user question cannot be emptyï¼')
                    continue
                    
                # æ„å»ºæ¶ˆæ¯
                messages.append({'role': 'user', 'content': query})

                print("æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...")
                # è¿è¡ŒåŠ©æ‰‹å¹¶å¤„ç†å“åº”
                response = []
                current_index = 0
                first_chunk = True
                for response_chunk in bot.run(messages=messages):
                    if first_chunk:
                        # å°è¯•è·å–å¹¶æ‰“å°å¬å›çš„æ–‡æ¡£å†…å®¹
                        # æ£€æŸ¥botæ˜¯å¦æœ‰retrieverå±æ€§
                        print("\n===== å¬å›çš„æ–‡æ¡£å†…å®¹ =====")
                        try:
                            # å°è¯•ä½¿ç”¨botçš„æ£€ç´¢åŠŸèƒ½
                            # è¿™é‡Œæˆ‘ä»¬åªæ˜¯æ‰“å°ä¿¡æ¯ï¼Œå› ä¸ºå…·ä½“çš„å®ç°ä¾èµ–äºbotçš„å†…éƒ¨ç»“æ„
                            print("ä½¿ç”¨å†…ç½®æ£€ç´¢åŠŸèƒ½æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯...")
                        except Exception as e:
                            print(f"æ£€ç´¢æ–‡æ¡£æ—¶å‡ºé”™: {e}")
                        print("===========================\n")
                        first_chunk = False

                    # The response is a list of messages. We are interested in the assistant's message.
                    if response_chunk and response_chunk[0]['role'] == 'assistant':
                        assistant_message = response_chunk[0]
                        new_content = assistant_message.get('content', '')
                        if new_content:
                            print(new_content[current_index:], end='', flush=True)
                            current_index = len(new_content)
                        else:
                            current_index = 0
                    
                    response = response_chunk
                
                print() # New line after streaming.

                messages.extend(response)
            except Exception as e:
                print(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
                print("è¯·é‡è¯•æˆ–è¾“å…¥æ–°çš„é—®é¢˜")
    except Exception as e:
        print(f"å¯åŠ¨ç»ˆç«¯æ¨¡å¼å¤±è´¥: {str(e)}")


def app_gui(mode: str = "full"):
    """å›¾å½¢ç•Œé¢æ¨¡å¼ï¼Œæä¾› Web å›¾å½¢ç•Œé¢"""
    try:
        print("æ­£åœ¨å¯åŠ¨ Web ç•Œé¢...")
        # åˆå§‹åŒ–åŠ©æ‰‹
        bot = bots.get(mode, bots["full"])
        
        # é…ç½®èŠå¤©ç•Œé¢ï¼Œåˆ—ä¸¾å…¸å‹é—®é¢˜
        chatbot_config = {
            'prompt.suggestions': [
                'ç”»ä¸€åªåœ¨å†™ä»£ç çš„çŒ«',
                'ä»‹ç»ä¸‹é›‡ä¸»è´£ä»»é™©',
                'å¸®æˆ‘ç”»ä¸€ä¸ªå®‡å®™é£èˆ¹ï¼Œç„¶åæŠŠå®ƒå˜æˆé»‘ç™½çš„',
                'é›‡ä¸»è´£ä»»é™©å’Œå·¥ä¼¤ä¿é™©æœ‰ä»€ä¹ˆä¸»è¦åŒºåˆ«ï¼Ÿ',
                'ä»‹ç»ä¸€ä¸‹å¹³å®‰å•†ä¸šç»¼åˆè´£ä»»ä¿é™©ï¼ˆäºšé©¬é€Šï¼‰çš„ä¿éšœèŒƒå›´ã€‚',
                'æ–½å·¥ä¿ä¸»è¦é€‚ç”¨äºå“ªäº›åœºæ™¯ï¼Ÿ',
                'æœ€è¿‘æœ‰ä»€ä¹ˆæ–°çš„ä¿é™©äº§å“æ¨èå—ï¼Ÿ'
            ]
        }
        print("Web ç•Œé¢å‡†å¤‡å°±ç»ªï¼Œæ­£åœ¨å¯åŠ¨æœåŠ¡...")
        # å¯åŠ¨ Web ç•Œé¢
        WebUI(
            bot,
            chatbot_config=chatbot_config
        ).run()
    except Exception as e:
        print(f"å¯åŠ¨ Web ç•Œé¢å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API Key é…ç½®")


def get_image_base64(image_path):
    """å°†å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸º Base64 ç¼–ç çš„å­—ç¬¦ä¸²"""
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode('utf-8')
    except Exception as e:
        print(f"Error reading image file: {e}")
        return ""
        
def load_css(css_path):
    """è¯»å– CSS æ–‡ä»¶å†…å®¹"""
    try:
        with open(css_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        print(f"Error reading css file: {e}")
        return ""

def main_gradio():
    """å¯åŠ¨è‡ªå®šä¹‰çš„ Gradio Web å›¾å½¢ç•Œé¢"""

    current_dir = os.path.dirname(os.path.abspath(__file__))
    static_dir_path = os.path.join(current_dir, "static")
    
    # --- Base64 åµŒå…¥å›¾ç‰‡ ---
    logo_path = os.path.join(static_dir_path, "logo.png")
    logo_base64 = get_image_base64(logo_path)
    logo_data_uri = f"data:image/png;base64,{logo_base64}"

    # --- è¯»å–å¹¶å†…è” CSS ---
    css_content = load_css(os.path.join(static_dir_path, "styles.css"))
    # ä¸º Logo æ·»åŠ å¤§å°é™åˆ¶
    css_content += "\n#logo-img { width: 40px !important; height: 40px !important; }"

    
    with gr.Blocks(css=css_content, theme=gr.themes.Soft(primary_hue="blue", secondary_hue="purple")) as demo:
        session_id = gr.State(get_session_id)
        mode = gr.State("full")  # é»˜è®¤æ¨¡å¼ä¸ºfull
        
        with gr.Row():
            with gr.Column(scale=2, elem_id="sidebar"):
                with gr.Row(elem_id="logo"):
                    # ä½¿ç”¨ Base64 Data URI ç›´æ¥åµŒå…¥ Logo
                    gr.HTML(f'<img id="logo-img" src="{logo_data_uri}" alt="logo">')
                    gr.HTML('<h1 id="logo-text">çŸ¥ä¹ç›´ç­”</h1>')
                
                gr.Button("ğŸ”  æœç´¢", elem_classes=["sidebar-btn", "active"])
                knowledge_btn = gr.Button("ğŸ“š  çŸ¥è¯†åº“", elem_classes="sidebar-btn")
                favorites_btn = gr.Button("â­  æ”¶è—", elem_classes="sidebar-btn")
                history_btn = gr.Button("ğŸ•’  å†å²", elem_classes="sidebar-btn")
            
            with gr.Column(scale=8, elem_id="main-chat"):
                with gr.Row(elem_id="chat-header"):
                    gr.HTML('<h1 id="chat-header-title">ç”¨æé—®å‘ç°ä¸–ç•Œ</h1><p id="chat-header-subtitle">è¾“å…¥ä½ çš„é—®é¢˜ï¼Œæˆ–ä½¿ç”¨ã€Œ@å¿«æ·å¼•ç”¨ã€å¯¹çŸ¥ä¹ç­”ä¸»ã€çŸ¥è¯†åº“è¿›è¡Œæé—®</p>')

                chatbot = gr.Chatbot(elem_id="chatbot", bubble_full_width=False, height=550)
                
                with gr.Row(elem_id="suggestion-row") as suggestion_row:
                    suggestions = ['ä»‹ç»ä¸‹é›‡ä¸»è´£ä»»é™©', 'é›‡ä¸»è´£ä»»é™©å’Œå·¥ä¼¤ä¿é™©æœ‰ä»€ä¹ˆä¸»è¦åŒºåˆ«ï¼Ÿ', 'æœ€è¿‘æœ‰ä»€ä¹ˆæ–°çš„ä¿é™©äº§å“æ¨èå—ï¼Ÿ']
                    suggestion_btns = []
                    for s in suggestions:
                        btn = gr.Button(s, elem_classes="suggestion-btn")
                        suggestion_btns.append(btn)
                
                with gr.Row(elem_id="input-container-wrapper"):
                    with gr.Row(elem_id="input-container"):
                        textbox = gr.Textbox(container=False, show_label=False, placeholder="è¾“å…¥ä½ çš„é—®é¢˜...", scale=10)
                        submit_btn = gr.Button("â†‘", scale=1, min_width=0, variant="primary")
        
        def on_submit(query, history):
            history.append([query, None])
            return "", history

        def on_suggestion_click(suggestion, history):
            history.append([suggestion, None])
            return "", history, gr.update(visible=False)
        
        def show_not_implemented_toast():
            gr.Info("åŠŸèƒ½æš‚æœªå®ç°ï¼Œæ•¬è¯·æœŸå¾…ï¼")

        knowledge_btn.click(show_not_implemented_toast, None, None)
        favorites_btn.click(show_not_implemented_toast, None, None)
        history_btn.click(show_not_implemented_toast, None, None)

        submit_event = textbox.submit(on_submit, [textbox, chatbot], [textbox, chatbot], queue=False)
        submit_event.then(lambda: gr.update(visible=False), None, suggestion_row)
        submit_event.then(stream_predict, [textbox, chatbot, session_id, mode], chatbot)

        click_event = submit_btn.click(on_submit, [textbox, chatbot], [textbox, chatbot], queue=False)
        click_event.then(lambda: gr.update(visible=False), None, suggestion_row)
        click_event.then(stream_predict, [textbox, chatbot, session_id, mode], chatbot)
        
        for btn in suggestion_btns:
            s_click_event = btn.click(on_suggestion_click, [btn, chatbot], [textbox, chatbot, suggestion_row], queue=False)
            s_click_event.then(stream_predict, [btn, chatbot, session_id, mode], chatbot)

    print("æ­£åœ¨å¯åŠ¨ AI åŠ©æ‰‹ Web ç•Œé¢ (æ•´åˆç‰ˆ)...")
    demo.launch()

def main():
    """ä¸»å‡½æ•° - å¯åŠ¨ç¨‹åº"""
    print("AI åŠ©æ‰‹å¯åŠ¨ä¸­...")
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. ç»ˆç«¯äº¤äº’æ¨¡å¼ (ç®€å•åŠŸèƒ½)")
    print("2. ç»ˆç«¯äº¤äº’æ¨¡å¼ (Elasticsearch)")
    print("3. ç»ˆç«¯äº¤äº’æ¨¡å¼ (RAG)")
    print("4. ç»ˆç«¯äº¤äº’æ¨¡å¼ (å®Œæ•´åŠŸèƒ½)")
    print("5. Web ç•Œé¢æ¨¡å¼ (ç®€å•åŠŸèƒ½)")
    print("6. Web ç•Œé¢æ¨¡å¼ (Elasticsearch)")
    print("7. Web ç•Œé¢æ¨¡å¼ (RAG)")
    print("8. Web ç•Œé¢æ¨¡å¼ (å®Œæ•´åŠŸèƒ½)")
    print("9. è‡ªå®šä¹‰ Gradio ç•Œé¢ (å®Œæ•´åŠŸèƒ½)")
    
    choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-9): ")
    
    modes = {
        "1": ("simple", "tui"),
        "2": ("elasticsearch", "tui"),
        "3": ("rag", "tui"),
        "4": ("full", "tui"),
        "5": ("simple", "gui"),
        "6": ("elasticsearch", "gui"),
        "7": ("rag", "gui"),
        "8": ("full", "gui"),
        "9": (None, "gradio")
    }
    
    if choice in modes:
        mode, interface = modes[choice]
        if interface == "tui":
            app_tui(mode)
        elif interface == "gui":
            app_gui(mode)
        elif interface == "gradio":
            main_gradio()
    else:
        print("æ— æ•ˆé€‰é¡¹ï¼Œå¯åŠ¨é»˜è®¤ Web ç•Œé¢æ¨¡å¼ (å®Œæ•´åŠŸèƒ½)")
        app_gui("full")

if __name__ == '__main__':
    main()
